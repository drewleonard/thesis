{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dateutil.parser\n",
    "import json\n",
    "import re\n",
    "import string \n",
    "import math\n",
    "from difflib import SequenceMatcher\n",
    "from urlparse import urlparse\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load master data\n",
    "path = \"~/Documents/thesis/data/csv/FacebookAds.csv\"\n",
    "df = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrub df of missing or unwanted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data into pd.df\n",
    "path = \"~/Documents/thesis/data/csv/FacebookAds.csv\"\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "# Remove rows with null AdText values\n",
    "df = df[pd.notnull(df['AdText'])]\n",
    "\n",
    "# Remove immediately unwanted columns\n",
    "# Either too unavailable or not useful\n",
    "df = df.drop(columns=[\n",
    "    'EndDate', 'Behaviors', 'PeopleWhoMatch', 'Placements', 'pages',\n",
    "    'FriendsOfConnections', 'ExcludedConnections', 'Gender', 'Generation',\n",
    "    'Politics', 'CustomAudience', 'SourceFile', 'SourceZip', 'Language'\n",
    "])\n",
    "\n",
    "# Remove rows will no CreationDate value\n",
    "df = df[pd.notnull(df['CreationDate'])]\n",
    "\n",
    "# Reset index after dropping columns\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# Fix float columns\n",
    "integer_cols = ['Clicks','Impressions','AdSpend']\n",
    "for n, e in df.iterrows():\n",
    "    for col in integer_cols:\n",
    "        if math.isnan(e[col]):\n",
    "            df.at[n,col] = 0.0\n",
    "            \n",
    "# Fix AdText column\n",
    "for n, e in enumerate(df['AdText']):\n",
    "    curr_e = re.sub(r'http\\S+', '', e)\n",
    "    curr_e = curr_e.replace('?????? ??? ????? ? ??????????', '')\n",
    "    curr_e = curr_e.replace('Subscribe to our channel:','')\n",
    "    curr_e = curr_e.replace('Follow my Facebook:','')\n",
    "    curr_e = curr_e.replace('Follow me on Instagram:','')\n",
    "    curr_e = curr_e.replace('Follow me on Twitter:','')\n",
    "    df.at[n, 'AdText'] = curr_e\n",
    "\n",
    "# Fix some string cols\n",
    "string_cols = ['LandingPage','Location','Interests','AdSpendCurrency']\n",
    "for string_col in string_cols:\n",
    "    df[string_col] = df[string_col].astype(str)\n",
    "    for n, e in enumerate(df[string_col]):\n",
    "        if e == 'nan':\n",
    "            df.at[n, string_col] = 'unavailable'\n",
    "\n",
    "# Remove rows with null AdText values\n",
    "df = df[pd.notnull(df['AdText'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create new columns for better covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AccountGroup\n",
    "with open('/Users/drewnleonard/Documents/thesis/data/json/group_keys.json') as f:\n",
    "    group_keys = json.load(f)\n",
    "AccountGroup = []\n",
    "for ad_id in df['AdID']:\n",
    "    \n",
    "    ad_id = str(ad_id)\n",
    "    \n",
    "    if ad_id in group_keys:\n",
    "        AccountGroup.append(group_keys[ad_id])\n",
    "    else:\n",
    "        AccountGroup.append('Unavailable')\n",
    "df['AccountGroup'] = AccountGroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_landing_pages = ['/',\n",
    " '/10718-take-part-in-black-pride-survey/',\n",
    " '/16383-st-louis-killer-cop-caught-in-on-camera/',\n",
    " '/4678-police-says-run-them-over-and-goes-scot-free/',\n",
    " '/6189-black-woman-found-dead-in-jail-cell-after-arguing-with-detention-officers/',\n",
    " '/6411-texas-police-officer-found-not-guilty-for-killing-a-black-woman/',\n",
    " '/6948-officers-violently-beat-and-arrest-teen-just-for-asking-question/',\n",
    " '/6980-baltimore-cop-drag-black-teen-from-home-without-warrant/',\n",
    " '/6984-man-set-free-after-10-years-in-prison-because-police-Iied-in-court/',\n",
    " '/7167-blm-members-arrested-for-counter-protest-against-white-power-rally-in-georgic/',\n",
    " '/7474-black-families-embark-on-homeschooling-because-of-racial-bias-and-safety-concerns/',\n",
    " '/7660-utah-school-defends-white-teachers-use-of-the-n-word-in-class/',\n",
    " '/7868-officer-puts-his-gun-he-used-in-killing-black-teen-on-auction/',\n",
    " '/8347-ohio-authorities-keep-their-eyes-shut-at-kkk-style-death/',\n",
    " '/9599-orlando-black-victims-need-support/',\n",
    " '/AdTargeting','/events/1140553372667995/',\n",
    " '/events/1486230091674577/',\n",
    " '/events/I748220542079708/','/us-news/2015/nov/19/syrian-refugees-in-america-fact-from-fiction-congress']\n",
    "\n",
    "def similar(a, b):\n",
    "    return SequenceMatcher(None, a, b).ratio()\n",
    "\n",
    "for n, e in df.iterrows():\n",
    "    \n",
    "    if e['AccountGroup'] != 'Unavailable':\n",
    "        continue\n",
    "    \n",
    "    landing_page = urlparse(e['LandingPage'])\n",
    "    path = landing_page.path\n",
    "    \n",
    "    if path in exclude_landing_pages:\n",
    "        continue\n",
    "    \n",
    "    path = ''.join([i for i in path if not i.isdigit()])\n",
    "    path = path.replace('/','')\n",
    "    path = path.replace('-', ' ')\n",
    "    \n",
    "    curr_max = {\n",
    "        'name': \"\",\n",
    "        'score': 0\n",
    "    }\n",
    "    \n",
    "    for group in set(df['AccountGroup']):\n",
    "        if similar(group, path) > 0.7 and similar(group, path) > curr_max['score']:\n",
    "            curr_max['name'] = group\n",
    "            curr_max['score'] = similar(group, path)\n",
    "    \n",
    "    if curr_max['name'] != '':\n",
    "        df.at[n, 'AccountGroup'] = curr_max['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AccountGroup clustering\n",
    "group_cluster_path = '/Users/drewnleonard/Documents/thesis/data/csv/groups_clusters.csv'\n",
    "group_cluster_df = pd.read_csv(group_cluster_path, names = [\"g1_id\", \"g1_name\", \"g2_id\", \"g2_name\"])\n",
    "\n",
    "cluster_map = {}\n",
    "for n, e in group_cluster_df.iterrows():\n",
    "    if e['g1_name']:\n",
    "        cluster_map[e['g1_name']] = 1\n",
    "    if e['g2_name']:\n",
    "        cluster_map[e['g2_name']] = 2\n",
    "\n",
    "\n",
    "cluster_list = []\n",
    "for n, e in df.iterrows():\n",
    "    \n",
    "    # Get account gruop name\n",
    "    account_group_name = e['AccountGroup']\n",
    "    \n",
    "    # If account group is in the map ...\n",
    "    if account_group_name in cluster_map:\n",
    "        cluster_list.append(cluster_map[account_group_name])\n",
    "    else:\n",
    "        cluster_list.append('Unavailable')\n",
    "        \n",
    "df['AccountGroupCluster'] = cluster_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CreationDateFormatted\n",
    "CreationDateFormatted = []\n",
    "for CreationDate in df['CreationDate']:\n",
    "    try:\n",
    "        new_date = dateutil.parser.parse(CreationDate[:-7]).date()\n",
    "        CreationDateFormatted.append(new_date)\n",
    "    except:\n",
    "        CreationDateFormatted.append(dateutil.parser.parse('2015-10-31'))\n",
    "df['CreationDateFormatted'] = CreationDateFormatted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "CreationDateInteger = []\n",
    "for creation_date in df['CreationDateFormatted']:\n",
    "    str_date = str(creation_date).split()[0]\n",
    "    date_int = int(str_date.replace('-',''))\n",
    "    CreationDateInteger.append(date_int)\n",
    "df['CreationDateInteger'] = CreationDateInteger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AgeAverage\n",
    "AgeAverage = []\n",
    "for age_string in df['Age']:\n",
    "    l = re.findall(r'\\d+', age_string)\n",
    "    l = [float(n) for n in l]\n",
    "    AgeAverage.append(sum(l) / float(len(l)))\n",
    "df['AgeAverage'] = AgeAverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AgeAverageBin\n",
    "df['AgeAverageBin'] = pd.qcut(df['AgeAverage'], 4, labels=[\"LowAge\",\"MidAge\",\"HighAge\"],duplicates='drop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AdSpendBin\n",
    "df['AdSpendBin'] = pd.qcut(df['AdSpend'], 3, labels=[\"low\",\"mid\",\"high\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ClicksBin\n",
    "df['ClicksBin'] = pd.qcut(df['Clicks'], 3, labels=[\"low\",\"mid\",\"high\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ImpressionsBin\n",
    "df[\"ImpressionsBin\"] = pd.qcut(df['Impressions'], 3, labels=[\"low\",\"mid\",\"high\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For All InterestSet \\in Advertisements:\n",
    "# For All InterestKeywords \\in InterestGroups:\n",
    "# If InterestKeywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "interests_path = \"/Users/drewnleonard/Documents/thesis/data/json/interest_groups_gold.json\"\n",
    "with open(interests_path) as f:\n",
    "    interest_keywords = json.load(f)\n",
    "\n",
    "# Run through interests\n",
    "interest_map = {}\n",
    "\n",
    "for n, unique_interest in enumerate(df['Interests'].unique()):\n",
    "        \n",
    "    # Put unique interest in lower case\n",
    "    unique_interest = unique_interest.lower()\n",
    "    \n",
    "    # Iterate over set of topics with interest keywords\n",
    "    for topic, keywords in interest_keywords.iteritems():\n",
    "        \n",
    "        for keyword in keywords:\n",
    "            if keyword in unique_interest:\n",
    "                \n",
    "                if unique_interest not in interest_map:\n",
    "                    interest_map[unique_interest] = {}\n",
    "                \n",
    "                if topic not in interest_map[unique_interest]:\n",
    "                    interest_map[unique_interest][topic] = 0\n",
    "                \n",
    "                interest_map[unique_interest][topic] += 1\n",
    "                \n",
    "\n",
    "for interest, topics in interest_map.iteritems():\n",
    "    \n",
    "    curr = {\n",
    "        'count': 0,\n",
    "        'name': ''\n",
    "    }\n",
    "     \n",
    "    for topic_name, topic_count in topics.iteritems():\n",
    "        \n",
    "        if topic_count > curr['count']:\n",
    "            curr['count'] = topic_count\n",
    "            curr['name'] = topic_name\n",
    "    \n",
    "    interest_map[interest] = curr['name']\n",
    "\n",
    "for n, e in enumerate(df['Interests']):\n",
    "    if e.lower() in interest_map:\n",
    "        df.at[n,'Interests'] = interest_map[e.lower()]\n",
    "    else:\n",
    "        df.at[n,'Interests'] = 'mixed'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('~/Documents/thesis/data/csv/fb_gold.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
