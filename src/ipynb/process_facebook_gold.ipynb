{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dateutil.parser\n",
    "import json\n",
    "import re\n",
    "import string \n",
    "import math\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load master data\n",
    "path = \"~/Documents/thesis/data/csv/FacebookAds.csv\"\n",
    "df = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrub df of missing or unwanted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data into pd.df\n",
    "path = \"~/Documents/thesis/data/csv/FacebookAds.csv\"\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "# Remove rows with null AdText values\n",
    "df = df[pd.notnull(df['AdText'])]\n",
    "\n",
    "# Remove immediately unwanted columns\n",
    "# Either too unavailable or not useful\n",
    "df = df.drop(columns=[\n",
    "    'EndDate', 'Behaviors', 'PeopleWhoMatch', 'Placements', 'pages',\n",
    "    'FriendsOfConnections', 'ExcludedConnections', 'Gender', 'Generation',\n",
    "    'Politics', 'CustomAudience', 'SourceFile', 'SourceZip', 'Language'\n",
    "])\n",
    "\n",
    "# Remove rows will no CreationDate value\n",
    "df = df[pd.notnull(df['CreationDate'])]\n",
    "\n",
    "# Reset index after dropping columns\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# Fix float columns\n",
    "integer_cols = ['Clicks','Impressions','AdSpend']\n",
    "for n, e in df.iterrows():\n",
    "    for col in integer_cols:\n",
    "        if math.isnan(e[col]):\n",
    "            df.at[n,col] = 0.0\n",
    "            \n",
    "# Fix AdText column\n",
    "for n, e in enumerate(df['AdText']):\n",
    "    curr_e = re.sub(r'http\\S+', '', e)\n",
    "    curr_e = curr_e.replace('?????? ??? ????? ? ??????????', '')\n",
    "    curr_e = curr_e.replace('Subscribe to our channel:','')\n",
    "    curr_e = curr_e.replace('Follow my Facebook:','')\n",
    "    curr_e = curr_e.replace('Follow me on Instagram:','')\n",
    "    curr_e = curr_e.replace('Follow me on Twitter:','')\n",
    "    df.at[n, 'AdText'] = curr_e\n",
    "\n",
    "# Fix some string cols\n",
    "string_cols = ['LandingPage','Location','Interests','AdSpendCurrency']\n",
    "for string_col in string_cols:\n",
    "    df[string_col] = df[string_col].astype(str)\n",
    "    for n, e in enumerate(df[string_col]):\n",
    "        if e == 'nan':\n",
    "            df.at[n, string_col] = 'unavailable'\n",
    "\n",
    "# Remove rows with null AdText values\n",
    "df = df[pd.notnull(df['AdText'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create new columns for better covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CreationDateFormatted\n",
    "CreationDateFormatted = []\n",
    "for CreationDate in df['CreationDate']:\n",
    "    try:\n",
    "        new_date = dateutil.parser.parse(CreationDate[:-7]).date()\n",
    "        CreationDateFormatted.append(new_date)\n",
    "    except:\n",
    "        CreationDateFormatted.append(dateutil.parser.parse('2015-10-31'))\n",
    "df['CreationDateFormatted'] = CreationDateFormatted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AgeAverage\n",
    "AgeAverage = []\n",
    "for age_string in df['Age']:\n",
    "    l = re.findall(r'\\d+', age_string)\n",
    "    l = [float(n) for n in l]\n",
    "    AgeAverage.append(sum(l) / float(len(l)))\n",
    "df['AgeAverage'] = AgeAverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AgeAverageBin\n",
    "df['AgeAverageBin'] = pd.qcut(df['AgeAverage'], 4, labels=[\"LowAge\",\"MidAge\",\"HighAge\"],duplicates='drop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AdSpendBin\n",
    "df['AdSpendBin'] = pd.qcut(df['AdSpend'], 3, labels=[\"low\",\"mid\",\"high\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ClicksBin\n",
    "df['ClicksBin'] = pd.qcut(df['Clicks'], 3, labels=[\"low\",\"mid\",\"high\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ImpressionsBin\n",
    "df[\"ImpressionsBin\"] = pd.qcut(df['Impressions'], 3, labels=[\"low\",\"mid\",\"high\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "interests_path = \"/Users/drewnleonard/Documents/thesis/data/json/interest_groups_gold.json\"\n",
    "with open(interests_path) as f:\n",
    "    interest_keywords = json.load(f)\n",
    "\n",
    "# Run through interests\n",
    "interest_map = {}\n",
    "\n",
    "for n, unique_interest in enumerate(df['Interests'].unique()):\n",
    "    \n",
    "    # Put unique interest in lower case\n",
    "    unique_interest = unique_interest.lower()\n",
    "    \n",
    "    # Arr to store found topics\n",
    "    found_topics = {}\n",
    "    \n",
    "    # Iterate over set of topics with interest keywords\n",
    "    for topic, keywords in interest_keywords.iteritems():\n",
    "        \n",
    "        for keyword in keywords:\n",
    "            if keyword in unique_interest:\n",
    "                if topic not in found_topics:\n",
    "                    found_topics[topic] = 0\n",
    "                found_topics[topic] += 1\n",
    "                \n",
    "    else:\n",
    "        interest_map[unique_interest] = found_topics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for interest, topics in interest_map.iteritems():\n",
    "    \n",
    "    curr = {\n",
    "        'count': 0,\n",
    "        'name': ''\n",
    "    }\n",
    "    \n",
    "    for topic_name, topic_count in topics.iteritems():\n",
    "        if topic_count > curr['count']:\n",
    "            curr['count'] = topic_count\n",
    "            curr['name'] = topic_name\n",
    "    \n",
    "    if curr['name'] == '':\n",
    "        curr['name'] = 'mixed'\n",
    "    \n",
    "    interest_map[interest] = curr['name']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n, e in enumerate(df['Interests']):\n",
    "    df.at[n,'Interests'] = interest_map[e.lower()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('~/Documents/thesis/data/csv/fb_gold.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # InterestsGroups\n",
    "\n",
    "# # Load mapped interests grups json file\n",
    "# interests_path = \"/Users/drewnleonard/Documents/thesis/data/json/interest_groups.json\"\n",
    "# with open(interests_path) as f:\n",
    "#     interests_groups_map = json.load(f)\n",
    "\n",
    "# for k, v in interests_groups_map.iteritems():\n",
    "#     v = [e.lower() for e in v]\n",
    "#     interests_groups_map[k] = set(v)\n",
    "\n",
    "# interests_group_master = {}\n",
    "    \n",
    "# for n, interests in enumerate(df['Interests']):\n",
    "    \n",
    "#     # Continue if there are no available interests\n",
    "#     if interests == 'Unavailable':\n",
    "#         continue\n",
    "    \n",
    "#     # Parse interests into list\n",
    "#     interests_list = interests.split(',')\n",
    "    \n",
    "#     found_interest_groups = {}\n",
    "    \n",
    "#     # Iterate over interests in list\n",
    "#     for interest in interests_list:\n",
    "        \n",
    "#         interest = interest.lower()\n",
    "        \n",
    "#         # Iterate over mapped groups\n",
    "#         for interest_group_title, interest_group_keywords in interests_groups_map.iteritems():\n",
    "            \n",
    "#             # For each mapped group, iterate over its keywords\n",
    "#             for keyword in interest_group_keywords:\n",
    "                    \n",
    "#                     # If keyword is in interest, record that and break\n",
    "#                     if keyword in interest:\n",
    "                        \n",
    "#                         if interest_group_title not in found_interest_groups:\n",
    "#                             found_interest_groups[interest_group_title] = 0\n",
    "                        \n",
    "#                         # Increment keyword's value \n",
    "#                         found_interest_groups[interest_group_title] += 1\n",
    "                        \n",
    "#                         break\n",
    "    \n",
    "#     curr_group_title = \"Unavailable\"\n",
    "#     curr_group_score = 0\n",
    "    \n",
    "#     for k, v in found_interest_groups.iteritems():\n",
    "#         curr_group_title = k if v > curr_group_score else curr_group_title\n",
    "        \n",
    "#     df.at[n, 'Interests'] = curr_group_title\n",
    "                               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Remove rows with null values\n",
    "# remove_rows_for_cols = ['AdText','AdID','CreationDate']\n",
    "# for col in remove_rows_for_cols:\n",
    "#     df = df[pd.notnull(df[col])]\n",
    "\n",
    "# # Reset index after removing rows\n",
    "# df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Remove rows without valid text\n",
    "# for n, e in enumerate(df['AdText']):\n",
    "#     if e and re.match(r'^[_\\W]+$', e):\n",
    "#         df.at[n, 'AdText'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Remove rows with null AdText values\n",
    "# for col in remove_rows_for_cols:\n",
    "#     df = df[pd.notnull(df['AdText'])]\n",
    "\n",
    "# # Reset index after removing rows\n",
    "# df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Scrub texts of social media phrases\n",
    "# social_media_phrases = [\"Subscribe to our channel:\",\"Follow my Facebook:\",\"Follow me on Instagram:\",\"Follow me on Twitter:\"]\n",
    "# for n, e in enumerate(df['AdText']):\n",
    "#     curr_e = e.lower()\n",
    "#     curr_e = re.sub(r'http\\S+', '', curr_e)\n",
    "#     [\n",
    "#         curr_e.replace(phrase, '') for phrase in social_media_phrases\n",
    "#     ]\n",
    "#     df.at[n, 'AdText'] = curr_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.drop(columns=[\n",
    "#     'EndDate', 'Behaviors', 'PeopleWhoMatch', 'Language','FriendsOfConnections', \n",
    "#     'ExcludedConnections', 'Gender', 'Generation',\n",
    "#     'Politics', 'CustomAudience', 'SourceFile', \n",
    "#     'SourceZip', 'pages', 'Location'\n",
    "# ])\n",
    "# df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Fix integer colums with null vals\n",
    "# integer_cols = ['Clicks','Impressions','AdSpend']\n",
    "# for integer_col in integer_cols:\n",
    "#     df[integer_col] = df[integer_col].fillna(0.0)\n",
    "    \n",
    "# # Fix string columns with null vals\n",
    "# string_cols = [\"LandingPage\", \"Interests\",\"AdSpendCurrency\"]\n",
    "# for string_col in string_cols:\n",
    "#     df[string_col] = df[string_col].fillna(\"Unavailable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Count null values as percentage for each column\n",
    "# total_vals = len(df)\n",
    "# for col in df.columns:\n",
    "#     null_vals = df[col].isnull().sum()\n",
    "#     print(\"{0}: {1}\".format(col, float(null_vals)/total_vals))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
