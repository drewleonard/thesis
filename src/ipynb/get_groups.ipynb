{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ad(path):\n",
    "    with open(path) as f:\n",
    "        return json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ad_group(ad):\n",
    "    \n",
    "    if 'second' not in ad:\n",
    "        return None\n",
    "    \n",
    "    # Index down to get ad text\n",
    "    ad_text = ad['second']['text']['textAnnotations'][0]['description'].splitlines()\n",
    "    \n",
    "    if 'instagram' in ad_text[0].lower() or 'sponsored' in ad_text[0].lower() or 'suggested' in ad_text[0].lower():\n",
    "        return ad_text[1]\n",
    "    return ad_text[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ad_id(ad):\n",
    "    \n",
    "    # Index down\n",
    "    ad_text = ad['first']['text']['fullTextAnnotation']['text']\n",
    "    ad_id_line = ad_text.splitlines()[0]\n",
    "    \n",
    "    # Parse id\n",
    "    ad_id = re.search(r'\\d+', ad_id_line).group()\n",
    "    \n",
    "    return ad_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "433\n"
     ]
    }
   ],
   "source": [
    "n = 0\n",
    "rootdir = '/Users/drewnleonard/Documents/thesis/data/json/ads/'\n",
    "for subdir, dirs, files in os.walk(rootdir):\n",
    "    for file in files:\n",
    "        path = os.path.join(subdir, file)\n",
    "        \n",
    "        if '.json' not in path:\n",
    "            continue\n",
    "        ad = load_ad(path)\n",
    "        \n",
    "        if 'second' not in ad:\n",
    "            n += 1\n",
    "print n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_first_page_text(text):\n",
    "    \n",
    "    remove_tokens = ['shared', 'added', 'updated']\n",
    "    for token in remove_tokens:\n",
    "        if token in text:\n",
    "            text = text.split(token,1)[0]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = set([\n",
    " u'blacktlivist',\n",
    " u'black matters',\n",
    " u'afrokingdom',\n",
    " u'american.made',\n",
    " u'american.veterans',\n",
    " u'angry eagle',\n",
    " u'army of jesus',\n",
    " u'back the badge',\n",
    " u'baltimore.blackvoice',\n",
    " u'being patriotic',\n",
    " u'bernie sanders for president',\n",
    " u'black baptist church',\n",
    " u'black edification',\n",
    " u'black excellence',\n",
    " u'black guns matter',\n",
    " u'black matters',\n",
    " u'black matters us',\n",
    " u'black4black',\n",
    " u'blackluive',\n",
    " u'blacks go viral',\n",
    " u'blackstagram',\n",
    " u'blacktivist',\n",
    " u'bm',\n",
    " u'born black',\n",
    " u'born liberal',\n",
    " u'brown power',\n",
    " u'cop block us',\n",
    " u'defend the 2nd',\n",
    " u\"don't shoot\",\n",
    " u'donald trump america',\n",
    " u'fit black',\n",
    " u'gov spending',\n",
    " u'heart of texas',\n",
    " u'hell_and_back',\n",
    " u'instagnan',\n",
    " u'isagan',\n",
    " u'justice for ezell ford and donnell thompson',\n",
    " u'l for life',\n",
    " u'lgbt united',\n",
    " u'liberty_rising',\n",
    " u'make america great again donald j trump',\n",
    " u'mbm',\n",
    " u'melanie black',\n",
    " u'melanie panther',\n",
    " u'memopolis',\n",
    " u'mericanfury',\n",
    " u'muslim voice',\n",
    " u'musliminst',\n",
    " u'native americans united',\n",
    " u\"nefertiti's community\",\n",
    " u'pan-african roots move',\n",
    " u'panther melanie',\n",
    " u\"patriot's heart\",\n",
    " u'pray4police',\n",
    " u'proud blacks',\n",
    " u'rebeltexas',\n",
    " u'secured borders',\n",
    " u'sincerely_black',\n",
    " u'south united',\n",
    " u'southern.rebel.pride',\n",
    " u'stand for freedom',\n",
    " u'stop a.l.',\n",
    " u'stop refugees',\n",
    " u'the red pill',\n",
    " u'trumpsters united',\n",
    " u'united muslims of america',\n",
    " u'veterans come first',\n",
    " u'watch the police',\n",
    " u'williams&kalvin',\n",
    " u'woke blacks'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14100\n",
      "14200\n",
      "14300\n",
      "14400\n",
      "14500\n",
      "14600\n",
      "14700\n",
      "14800\n",
      "14900\n",
      "15000\n",
      "15100\n",
      "15200\n",
      "15300\n",
      "15400\n",
      "15500\n",
      "15600\n",
      "15700\n",
      "15800\n",
      "15900\n",
      "16000\n",
      "16100\n",
      "16200\n",
      "16300\n",
      "16400\n",
      "16500\n",
      "16600\n",
      "16700\n",
      "16800\n",
      "16900\n",
      "17000\n",
      "17100\n",
      "17200\n",
      "17300\n",
      "17400\n",
      "17500\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "rootdir = '/Users/drewnleonard/Documents/thesis/data/json/ads/'\n",
    "for subdir, dirs, files in os.walk(rootdir):\n",
    "    for file in files:\n",
    "        \n",
    "        n += 1\n",
    "        if n % 100 == 0:\n",
    "            print n\n",
    "            \n",
    "        path = os.path.join(subdir, file)\n",
    "        if '.json' not in path:\n",
    "            continue\n",
    "        ad = load_ad(path)\n",
    "        \n",
    "        if 'second' not in ad:\n",
    "            continue\n",
    "        \n",
    "        ad_text = ad['second']['text']['textAnnotations'][0]['description'].splitlines()\n",
    "        found_group = clean_first_page_text(ad_text[0]).lower()\n",
    "        \n",
    "        next_page_tokens = ['like page', 'instagram']\n",
    "        for next_page_tokens in next_page_tokens:\n",
    "            if next_page_tokens in found_group:\n",
    "                found_group = ad_text[1].lower()\n",
    "        \n",
    "        found = False\n",
    "        for group in groups:\n",
    "            if found_group in group or group in found_group:\n",
    "                found_group = group\n",
    "                found = True\n",
    "                break\n",
    "        \n",
    "        if 'ad creation date' in found_group or 'ad end date' in found_group or 'ad impressions' in found_group or not found:\n",
    "            continue\n",
    "        \n",
    "        results[get_ad_id(ad)] = found_group\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: '~/Documents/thesis/data/json/group_keys.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-118-5c76f71d848b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'~/Documents/thesis/data/json/group_keys.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: '~/Documents/thesis/data/json/group_keys.json'"
     ]
    }
   ],
   "source": [
    "json.dump(results, open('~/Documents/thesis/data/json/group_keys.json', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
