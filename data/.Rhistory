install.packages(tidyverse)
install.packages("tidyverse")
Library(tidyverse)
library(tidyverse)
install.packages("swirl")
library(swirl)
swirl()
# library(rlang)
# library(data.table)
library(texteffect)
library(tidyverse)
library(tm)
library(textstem)
install.packages("tm", repos = "https://cran.revolutionanalytics.com")
library(tm)
install.packages("rlang", repos = "https://cran.revolutionanalytics.com")
install.packages("rlang", repos = "https://cran.revolutionanalytics.com")
install.packages("data.table", repos = "https://cran.revolutionanalytics.com")
library(rlang)
library(data.table)
library(texteffect)
library(tidyverse)
library(tm)
library(textstem)
install.packages("textstem", repos = "https://cran.revolutionanalytics.com")
install.packages("textstem", repos = "https://cran.revolutionanalytics.com", dependencies = TRUE)
install.packages("data.table", repos = "https://cran.revolutionanalytics.com", dependencies = TRUE)
install.packages("textstem", repos = "https://cran.revolutionanalytics.com", dependencies = TRUE)
library(data.table)
install.packages("tidyverse", repos = "https://cran.revolutionanalytics.com", dependencies = TRUE)
library(tidyverse)
library(tm)
library(textstem)
install.packages("textstem", repos = "https://cran.revolutionanalytics.com", dependencies = TRUE)
install.packages("textstem", repos = "https://cran.revolutionanalytics.com", dependencies = TRUE)
rm(list = ls())
setwd('~/Documents/thesis/data/')
library(rlang)
library(data.table)
library(texteffect)
library(tidyr)
library(dplyr)
library(readr)
library(tm)
library(textstem)
library(stringr)
library(tokenizers)
# Function for getting image n from tag
get_image_n <- function(image_tag) {
as.numeric(str_extract_all(image_tag, "[0-9]+")[[1]])
}
# Function for removing punctuation besides hashtag
remove_punctiation_helper <- function(x) {
x <- gsub("#", "\002", x)
x <- gsub("_", "\003", x)
x <- gsub("[[:punct:]]+", "", x)
x <- gsub("\002", "#", x, fixed = TRUE)
gsub("\003", "_", x, fixed = TRUE)
}
remove_punctiation <-
function (x, preserve_intra_word_dashes = FALSE) {
if (preserve_intra_word_dashes) {
x <- gsub("(\\w)-(\\w)", "\\1\001\\2", x)
x <- remove_punctiation_helper(x)
gsub("\001", "-", x, fixed = TRUE)
} else {
remove_punctiation_helper(x)
}
}
# Function to collapse hashtags to lemmas
collapse_punctuation <- function (x) {
x <- gsub("# ", "#", x, fixed = TRUE)
gsub(" _ ", "_", x, fixed = TRUE)
}
# Function to remove common terms
remove_common_terms <- function (x, pct) {
x[, slam::col_sums(x) / nrow(x) <= pct]
}
sibp_amce_temp <-
function(sibp.fit,
X,
Y,
G = NULL,
seed = 0,
level = 0.05,
thresh = 0.9) {
# Want it to be the case that G %*% beta selects the correct beta
if (is.null(G)) {
G <- matrix(1, nrow = nrow(X), ncol = 1)
}
set.seed(seed)
G.test <- G[sibp.fit$test.ind, , drop = FALSE]
Z.test <- infer_Z(sibp.fit, X)
Y.test <- (Y[sibp.fit$test.ind] - sibp.fit$meanY) / sibp.fit$sdY
Z.hard <-
apply(Z.test, 2, function(z)
sapply(z, function(zi)
ifelse(zi >= 0.9, 1, 0)))
L <- sibp.fit$L
K <- sibp.fit$K
if (L == 1) {
fit <- lm(Y.test ~ Z.hard)
}
else{
rhsmat <- c()
for (l in 1:L) {
rhsmat <- cbind(rhsmat, Z.hard * G.test[, l])
}
fit <- lm(Y.test ~ -1 + as.matrix(G.test) + rhsmat)
}
ci.bounds <-
cbind(
coef(fit) + qnorm(level / 2) * summary(fit)$coefficients[, 2],
coef(fit) + qnorm(1 - level / 2) * summary(fit)$coefficients[, 2]
)
cidf <- data.frame(
x = 1:((K + 1) * L),
effect = coef(fit),
L = ci.bounds[, 1],
U = ci.bounds[, 2]
)
cidf[, -1] <- cidf[, -1] * sibp.fit$sdY
sibp.amce <- cidf
return(sibp.amce)
}
# Load survey data
# 3259 responses
df_survey <- read.csv('/csv/survey/IRA.csv')
# Load survey data
# 3259 responses
df_survey <- read.csv('csv/survey/IRA.csv')
